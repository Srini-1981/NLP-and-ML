{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose of this Notebook\n",
    "* Typical chatbot needs to understand the intent (in layman terms needs to understand the question or what has been asked in the interaction in order to answer the question). Suppose if you are building a FAQ chatbot and you have 1K question and answers, we need to almost build 1K intents so that bot can answer the each question by understanding the intent. Suppose for a customer, if the FAQ size increases to 10K, building 10K intents is viable and bot able to scale to the incremental solution?\n",
    "* How can we solve this problem without writing the intents and enable bot to scale?\n",
    "* This solution can also be used for search indexing \n",
    "* This can be integrated to chatbot or it can also function as independent solution\n",
    "\n",
    "#### Theoritical solution\n",
    "* If we think broadly, all we need to do is to find the right question from the matrix of question and answers for which the question is asked, if we are able to do so then we can pull the answer from the index.\n",
    "* We will use soft cosine similarity from gensim in this notebook or to say in overall algorithm.\n",
    "\n",
    "#### Other similar solutions\n",
    "* We can do or achieve the same using other gensim similarity matching algorithms, what to use is based on the data and problem statement. Some similarities work better on word counts such as count vectorizer, tf-idf (term frequency inverse document frequency), etc. \n",
    "    * We have sample solution built based on tf-idf for the same dataset\n",
    "    * Solution built based on document to vector (doc2vec) for the same dataset\n",
    "    * Solution is available using word mover distance (wmd) for the same dataset\n",
    "\n",
    "#### References\n",
    "* https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
    "* https://www.machinelearningplus.com/nlp/gensim-tutorial/#18howtocomputesimilaritymetricslikecosinesimilarityandsoftcosinesimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all package imports \n",
    "import os\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import Word2Vec, WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix\n",
    "\n",
    "# Below import and download is not required to load each and every time, do as required\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame the data path for the data load (in this case it is csv file)\n",
    "root_dir = \".\"\n",
    "data_dir = \"data\"\n",
    "data_file = \"co_browsing_faq.csv\"\n",
    "data_path = os.path.join(root_dir, data_dir, data_file)\n",
    "\n",
    "# Just cross for the path framed\n",
    "#data_path\n",
    "\n",
    "# Import Data\n",
    "data = pd.read_csv(data_path, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cost of Living for Your Location, considered for income after retirement',\n",
       " 'Accounting for Taxes on Withdrawals',\n",
       " 'What if I want to plan to leave investments to my heirs?',\n",
       " \"How can I plan for retirement when I don't know anything about retirement\",\n",
       " 'What about If I retire early?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some of the rows \n",
    "#data.head()\n",
    "#data.tail()\n",
    "list(data['question'][10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"you've\", \"you'll\", \"you'd\", 'your', 'yours']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stop words from nltk\n",
    "stopWords = stopwords.words('english')\n",
    "# Inspect some stop words\n",
    "stopWords[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pre-processing data\n",
    "def clean_data(sentence):\n",
    "    # convert to lowercase, ignore all special characters - \n",
    "    # keep only alpha-numericals and spaces (not removing full-stop here)\n",
    "    sentence = re.sub(r'[^A-Za-z0-9\\s.]', r'', str(sentence).lower())\n",
    "    sentence = re.sub(r'\\n', r' ', sentence)\n",
    "    \n",
    "    # remove stop words\n",
    "    sentence = \" \".join([word for word in sentence.split() if word not in stopWords])\n",
    "    \n",
    "    return sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cost', 'living', 'location', 'considered', 'income', 'retirement'],\n",
       " ['accounting', 'taxes', 'withdrawals'],\n",
       " ['want', 'plan', 'leave', 'investments', 'heirs'],\n",
       " ['plan', 'retirement', 'dont', 'know', 'anything', 'retirement'],\n",
       " ['retire', 'early']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-process all the questions from the data frame\n",
    "questions_list = data.question.map(lambda x: clean_data(x))\n",
    "# Convert the questions to list again, the output of this will be list of lists (this format is required for the algorithm)\n",
    "questions_list = questions_list.tolist()\n",
    "# Inspect some of the questions after data clean up\n",
    "questions_list[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to train word-vectors\n",
    "# Using below we can train/build our own word to vector embeddings \n",
    "\n",
    "#w2v_model = Word2Vec(questions_list, size=50, min_count=1, iter=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-02 16:23:23,596 : INFO : loading projection weights from C:\\Users\\mommasani.srinivasul/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2020-03-02 16:27:15,467 : INFO : loaded (3000000, 300) matrix from C:\\Users\\mommasani.srinivasul/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Using below, we are loading pre-trained word vectors from the large corpus, list of all pre-trained word vectors available in \n",
    "gensim, below link provides the details.\n",
    "https://github.com/RaRe-Technologies/gensim-data\n",
    "\"\"\"\n",
    "#w2v_model = api.load(\"glove-wiki-gigaword-50\")\n",
    "# This takes 3-4 minutes to load, the projection weights for below pre-trained word2vec is around 1.7GB\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13682444\n",
      "[('retirment', 0.7519336938858032), ('retire', 0.7195518016815186), ('Retirement', 0.6784062385559082), ('retiring', 0.6532286405563354), ('retirements', 0.6454570889472961), ('pension', 0.6300544142723083), ('retirees', 0.6023612022399902), ('pensions', 0.5700603723526001), ('retires', 0.562114417552948), ('retired', 0.5513665676116943)]\n",
      "Wall time: 585 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(w2v_model.similarity('retirement','planning'))\n",
    "print(w2v_model.most_similar('retirement'))\n",
    "#print(w2v_model.wv['save'])\n",
    "#print(len(w2v_model.wv['save']))\n",
    "#print(len(w2v_model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mommasani.srinivasul\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "2020-03-02 16:30:59,889 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-03-02 16:30:59,892 : INFO : built Dictionary(92 unique tokens: ['get', 'planning', 'retirement', 'started', 'plan']...) from 34 documents (total 161 corpus positions)\n",
      "2020-03-02 16:30:59,897 : INFO : constructing a sparse term similarity matrix using <gensim.models.keyedvectors.WordEmbeddingSimilarityIndex object at 0x000001729825B348>\n",
      "2020-03-02 16:30:59,898 : INFO : iterating over columns in dictionary order\n",
      "2020-03-02 16:30:59,901 : INFO : PROGRESS: at 1.09% columns (1 / 92, 1.086957% density, 1.086957% projected density)\n",
      "2020-03-02 16:31:35,711 : INFO : constructed a sparse term similarity matrix with 2.670132% density\n"
     ]
    }
   ],
   "source": [
    "# Construct term simiarity index the trained or pre-trained word 2 vectors\n",
    "termsim_index = WordEmbeddingSimilarityIndex(w2v_model.wv)\n",
    "# Construct the dictionary from our documents\n",
    "dictionary = Dictionary(questions_list)\n",
    "# Construct document to bag of words using the dictionary built above\n",
    "bow_corpus = [dictionary.doc2bow(question) for question in questions_list]\n",
    "# Construct similarity matrix using term similarity index built from word2vec and from the document dictionary\n",
    "similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary)  \n",
    "# Construct final document similarity index\n",
    "scs_sim_index = SoftCosineSimilarity(bow_corpus, similarity_matrix, num_best=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data before inferencing\n",
    "def clean_data_inference(sentence):\n",
    "    # convert to lowercase, ignore all special characters - \n",
    "    # keep only alpha-numericals and spaces (not removing full-stop here)\n",
    "    sentence = re.sub(r'[^A-Za-z0-9\\s.]', r'', str(sentence).lower())\n",
    "    sentence = re.sub(r'\\n', r' ', sentence)\n",
    "    \n",
    "    return sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence score --> 0.9999999403953552 for record --> What about If I retire early?\n",
      "confidence score --> 0.36610791087150574 for record --> I want to plan for my retirement\n",
      "confidence score --> 0.36610791087150574 for record --> Cost of Living for Your Location, considered for income after retirement\n",
      "confidence score --> 0.36610791087150574 for record --> Is it possible to hold more than one account under retirement\n",
      "confidence score --> 0.36610791087150574 for record --> Can I hold non-dollar currencies in my retirement fund?\n",
      "confidence score --> 0.36610791087150574 for record --> How often should I rebalance my retirement account?\n",
      "confidence score --> 0.36610791087150574 for record --> How can I plan for retirement when I don't know anything about retirement\n",
      "confidence score --> 0.36610791087150574 for record --> Would it be possible to transfer other retirement plans under Digital adviser\n",
      "confidence score --> 0.36610791087150574 for record --> Time Horizon for Retirement planning\n",
      "confidence score --> 0.36610791087150574 for record --> How can I add other retirement income sources?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mommasani.srinivasul\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\similarities\\termsim.py:358: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Y = np.multiply(Y, 1 / np.sqrt(Y_norm))\n",
      "C:\\Users\\mommasani.srinivasul\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\similarities\\termsim.py:358: RuntimeWarning: invalid value encountered in multiply\n",
      "  Y = np.multiply(Y, 1 / np.sqrt(Y_norm))\n"
     ]
    }
   ],
   "source": [
    "# Make a query for inferencing\n",
    "query = 'retire early'\n",
    "query = clean_data(query)\n",
    "#query = clean_data_inference(query)\n",
    "#print(query)\n",
    "\n",
    "# Calculate similarity of query to each doc from bow_corpus\n",
    "scs_sims = scs_sim_index[dictionary.doc2bow(query)]\n",
    "\n",
    "# Print the inferences or questions with their confidence scores \n",
    "if(len(scs_sims) > 0):\n",
    "    for i in range(len(scs_sims)):\n",
    "        print(\"confidence score --> {} for record --> {}\" .format(scs_sims[i][1], data.question[scs_sims[i][0]]))\n",
    "else:\n",
    "    print(\"search doesnt return anything\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer --> If you plan on retiring early, you can enter the details in retirement planning simulator and assess the amount you would be left with by the time of retirement.\n",
      "answer --> Please provide your income and age, to plan for retirement.\n",
      "answer --> While it's common to retire where you lived during your working years, your retirement location may be different. By default, we assume you'll continue to live where you do now.\n",
      "answer --> Yes. Each investment account considered as a separate goal\n",
      "answer --> Yes. Our system is capable of handling non-dollar currencies as well in retirement fund.\n",
      "answer --> The decision to rebalance your retirement account should be made based on your desired asset allocation. This depends on your age and your desired risk level. \n",
      "answer --> The answer depends on your retirement goals and when you plan to retire. The earlier you want to retire, the more you will need to save.\n",
      "answer --> Right now it is not possible. This feature is in the roadmap for development.\n",
      "answer --> We default your life expectancy to 85 years old, which determines how many years you'll be spending for. You can adjust the time horizon.\n",
      "answer --> In the retirement simulation process, you can enter any other pension or retirement plans held.\n"
     ]
    }
   ],
   "source": [
    "# In case if you want to see or print the answers for above question(s)\n",
    "if(len(scs_sims) > 0):\n",
    "    for i in range(len(scs_sims)):\n",
    "        print(\"answer --> {}\" .format(data.answer[scs_sims[i][0]]))\n",
    "else:\n",
    "    print(\"search doesnt return anything\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
